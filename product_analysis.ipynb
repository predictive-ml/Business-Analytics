{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECRID  PRODUCT COLLECTION COMPARATIVE ANALYSIS\n",
    "\n",
    "\n",
    "<span style=\"color: gray; font-size:1em;\">January-2020</span>\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "* [Objective](#objective)\n",
    "\n",
    "* [Section One - Import Data into IDE](#import_data)\n",
    "    * [Part I - Gathering Data](#gather_data)\n",
    "    * [Part II - Assessing Data](#assess_data)\n",
    "    * [Part III - Cleaning Data](#clean_data)\n",
    "    \n",
    "* [Section Two - Dataset of Interest](#dataset)\n",
    "\n",
    "    * [Variable 1 - display name](#display_name)\n",
    "\n",
    "    * [Variable 2 - type of material](#material)\n",
    "     * [Vintage Analysis](#vintage)\n",
    "     * [Original Analysis](#original)\n",
    "     * [Matte Analysis](#matte)\n",
    "     * [combined collection dataset](#collectionsdf)\n",
    "     \n",
    "    * [Variable 3 - shipping country](#shipping_country)\n",
    "    \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='objective'></a>\n",
    "## Objective\n",
    "\n",
    "SECRID is a business entity based in the Netherlands. It produces, stocks and sells designer wallets, particularly leather based wallets in more than 100 countries all over the world.\n",
    "\n",
    "The objective of this notebook is to inspect the trend of sales data for the 2015 to 2019 calendar years and compare Vintage, Original and Matte product collections of the top five (5) revenue generating countries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#import_data'></a>\n",
    "## Section One : Import Data into IDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather_data'></a>\n",
    "## Part I : Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import read_excel\n",
    "\n",
    "import zipfile\n",
    "import xlsxwriter\n",
    "\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(11, 4)})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as mpl_dates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import six\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# environment settings:\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_column',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_seq_items',None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('expand_frame_repr', True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load .xlxs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sales 2015 \n",
    "df1 = pd.read_excel('SECRID_DATA.xlsx',0) #load first spreadsheet of SECRID DATA.xlxs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()# preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sales 2016 \n",
    "df2 = pd.read_excel('SECRID_DATA.xlsx',1) #load second spreadsheet of SECRID DATA.xlxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()# preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sales 2017\n",
    "df3 = pd.read_excel('SECRID_DATA.xlsx',2)  #load third spreadsheet ofSECRID DATA.xlxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()# preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sales 2018\n",
    "df4 = pd.read_excel('SECRID_DATA.xlsx',3)  #load fourth spreadsheet of SECRID DATA.xlxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()# preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sales 2019\n",
    "df5 = pd.read_excel('SECRID_DATA.xlsx',4)  #load fifth spreadsheet of SECRID DATA.xlxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()# preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine df1 - df5  into one complete dataframe 'df'\n",
    "df = pd.concat([df1, df2, df3, df4, df5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess_data'></a>\n",
    "## Part II - Assessing  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head() #preview first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() #preview last five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check size of the dataframe \n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list names of columns in dataframe\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View info of the dataframe \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view some of the core statistics about columns\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the Data types (dtypes) of each column in Dataframe\n",
    "df.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sum of duplicate rows\n",
    "df.duplicated().sum() # returns a Boolean Series with True value for each duplicated row and sums them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the number of unique elements in each column\n",
    "print(df.nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count() #returns the number of non-missing values for each column or row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total missing values(NaN) in a DataFrame\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of NaN for each column in DataFrame\n",
    "print(df.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='issues'></a>\n",
    "**Quality issues**\n",
    " * Rename column names to have clear, descriptive names in small letters according to best practice. Column 'name' can be renamed to 'customer_name' and column 'material' can be renamed to 'type_of_material'\n",
    " * Set to columns to appropriate category data type: 'internal_id', 'document_number', 'customer_name', 'customer _category', 'retailer_role', 'shipping_country', 'item', 'display_name', 'pim_category','type_of_material', \n",
    "   'pim_colour', 'wsl', 'while_stock_lasts' and 'cardprotector_colour' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean_data'></a>\n",
    "## Part III - Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of original DataFrame\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing messy column names\n",
    "df_copy.columns = df_copy.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list names of columns in dataframe\n",
    "df_copy.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names using rename function\n",
    "df_copy.rename(columns={                                                 \n",
    "                         'name':'customer_name',                        \n",
    "                         'wsl_+':'wsl',\n",
    "                         'material':'type_of_material' }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.columns #List of column names in df_clean Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "<br>Set appropriate data types for fields mentioned in the [Quality issues](#issues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .astype to change data type of dataframe columns\n",
    "df_copy = df_copy.astype({\"internal_id\":'category',\"document_number\":'category',\"shipping_address_1\":'category',\"shipping_address_2\":'category',\"shipping_city\":'category',\"shipping_zip\":'category',\"shipping_state/province\":'category', \"customer_name\":'category', \"customer_category\":'category', \"retailer_role\":'category', \"shipping_country\":'category', \"item\":'category',\"display_name\":'category', \"pim_category\":'category', \"type_of_material\":'category', \"pim_colour\":'category',\"wsl\":'category', \"while_stock_lasts\":'category', \"cardprotector_colour\":'category'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view some of the core statistics about columns\n",
    "df_copy.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### content structure of sales dataset\n",
    "The sales data contains 24 columns (variables) and 2,021,470 rows (entries). \n",
    "This is evidence that 2,021,470 sale transactions were completed in the January 2015 – July 2019 period for SECRID business. The dataset contained features about:\n",
    "\n",
    "* Products for sale: item, display_name, pim_category, pim_colour, type_of_material and cardprotector_colour\n",
    "* The country the item was shipped to : shipping_country  \n",
    "* Customer data:  customer_name, customer_category and retailer_role\n",
    "* Sale transactions: internal_id, document_number, quantity, amount, amount(foreign_currency) and date\n",
    "\n",
    "\n",
    "### Detected Missing Values\n",
    "A null value is a value in a field that appears to be blank. A null value is a field with no value. \n",
    "The table below indicates the number and  the resulting percentage of missing values per column.This able is manually created with results from running; **df.count()** to get Value Count of non-missing values in a column and \n",
    "**print(df.isnull().sum())** which will give the count number of NaN for each column in DataFrame.\n",
    "\n",
    "| Variable Name  | Value Count| Number Of Missing Values| % Of Missing Values\n",
    "| -------------  | ------------- |------------- |-------------\n",
    "| internal_id    | 2,021,470  |0 |0%\n",
    "| document_number| 2,021,470  |0 |0%\n",
    "| date           | 2,021,470  |0 |0%\n",
    "| date_created   | 2,021,470  |0 |0%\n",
    "| customer_name  | 2,021,470  |0 |0%\n",
    "| customer_category  | 2,015,375  |6,095     |0.30%\n",
    "| retailer_role      | 201,788    |1,819,682 |90.02%\n",
    "| shipping_address_1 | 2,011,883  |9,587     |0.47%\n",
    "| shipping_address_2 | 367,598    |1,653,872 |81.82%\n",
    "| shipping_city      | 2,012,657  |8,813 |0.44%\n",
    "| shipping_zip       | 1,990,236  |31,234|1.55%\n",
    "| shipping_state/province |395,792 |1,625,678 |80.42%\n",
    "| shipping_country   |2,014,891   |6,579 |0.33%\n",
    "| item               | 2,021,470  |0 |0%\n",
    "| display_name       | 2,021,470  |0 |0%\n",
    "| quantity           | 2,021,470  |0 |0%\n",
    "| amount             | 2,021,470  |0 |0%\n",
    "| amount_foreign_currency | 2,021,470 |0 |0%\n",
    "| type_of_material        | 1,941,770 |79,700 |3.94%\n",
    "| pim_category            | 1,944,252 |77,218 |3.82%\n",
    "| pim_colour              | 1,933,547 |87,923|4.35%\n",
    "| wsl_+                   | 2,021,470 |0     |0%\n",
    "| while_stock_lasts       | 2,021,470 |0     |0%\n",
    "| cardprotector_colour    | 1,877,516 |143,954 |7.12%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>\n",
    "## DATASET OF INTEREST\n",
    "\n",
    "In order to meet the objective, we shall extract the transactions of interest. These are transactions where the quantity is positive (>0) and the amount is positive (>0). This implies that item(s) were sold and revenue was generated for the business.  \n",
    "\n",
    "We shall further filter and create datasets where Vintage, Original and Matte items were sold. This dataset will be  filtered further to include only the top five(5) revenue generating shipping countries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows with positive values in Quantity column and Amount column\n",
    "# df_clean consits of transactions that bring in revenue\n",
    "df_clean = df_copy[(df_copy.amount>0) & (df_copy.quantity>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column 'year' that registered year sale transaction was held(helps with analysis)\n",
    "df_clean['year'] = df_clean.date.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head() #preview five first rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='display_name'></a>\n",
    "## VARIABLE : display_name\n",
    "\n",
    "We shall asses this variable because it gives a detailed chracteristic of item such as the 'pim_category', 'type_of_material' and 'colour'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.display_name.describe() #overview of variable; count, unique, top,freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all display_name categories\n",
    "print(df_clean.display_name.cat.categories) # Get list of categories in categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.display_name.value_counts() #count per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of missing values in display_name column\n",
    "print(df_clean.display_name.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='material'></a>\n",
    "## VARIABLE : type_of_material\n",
    "\n",
    "This variable is of interest as it is where we shall access the type of material e.g vintage, original or matte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.type_of_material.describe() #overview of variable; count, unique, top,freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Types of material used in production\n",
    "print (df_clean.type_of_material.cat.categories) # Get list of categories in categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.type_of_material.value_counts() #count per sale transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of missing values in type of material column\n",
    "print(df_clean.type_of_material.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "This column indicates the type of material used in creating the product.\n",
    "The business uses 29 unique types of material. This column has 75,661 missing values after filtering 'positive' sale transactions.**Vintage** category has the highest frequency of 'positive'/revenue generating sale transactions at 549,615."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id='vintage'></a>\n",
    "### VINTAGE PRODUCT ANALYSIS\n",
    "\n",
    "vintage consits of the follwing display items;\n",
    "      \n",
    "       'Miniwallet Vintage Black', 'Miniwallet Vintage Blue',\n",
    "       'Miniwallet Vintage Brown', 'Miniwallet Vintage Chocolate',\n",
    "       'Miniwallet Vintage Cognac', 'Miniwallet Vintage Cognac-Rust',\n",
    "       'Miniwallet Vintage Concrete', 'Miniwallet Vintage Grey',\n",
    "       'Miniwallet Vintage Grey-Black', 'Miniwallet Vintage Ochre',\n",
    "       'Miniwallet Vintage Olive-Black', 'Miniwallet Vintage Rose'\n",
    "       \n",
    "       'Slimwallet Vintage Black', 'Slimwallet Vintage Blue',\n",
    "       'Slimwallet Vintage Blue Silver', 'Slimwallet Vintage Brown',\n",
    "       'Slimwallet Vintage Chocolate', 'Slimwallet Vintage Cognac',\n",
    "       'Slimwallet Vintage Cognac-Rust', 'Slimwallet Vintage Grey-Black',\n",
    "       'Slimwallet Vintage Ochre', 'Slimwallet Vintage Olive-Black'\n",
    "       \n",
    "       'Twinwallet Vintage Black', 'Twinwallet Vintage Blue',\n",
    "       'Twinwallet Vintage Brown', 'Twinwallet Vintage Chocolate',\n",
    "       'Twinwallet Vintage Cognac', 'Twinwallet Vintage Ochre'\n",
    "       \n",
    "       'PromoSales Miniwallet Vintage Cognac-Rust'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only type of material of interest ('Vintage')\n",
    "# after manually assesing the dataframe incompletevintagedf, we find it is missing 'Slimwallet Vintage Blue Silver' and 'Twinwallet Vintage Blue\n",
    "incompletevintagedf =df_clean[(df_clean.type_of_material == 'Vintage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a dataframe with the missing display items\n",
    "# these missing items were in the rows with missing values in 'type_of_material' column\n",
    "missing_vintage = df_clean[(df_clean.display_name == 'Slimwallet Vintage Blue Silver') | (df_clean.display_name == 'Twinwallet Vintage Blue')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vintage.head() # preview first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine incompletevintagedf and missingvintage into one complete dataframe 'vintagedf'\n",
    "vintagedf = pd.concat([missing_vintage, incompletevintagedf]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this new column will help us uniquely identify vintage dataframe of data once it is combined with the original and matte dataframes\n",
    "#insert new column with value 'vint'\n",
    "vintagedf['collection']='vint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintagedf.head() #preview first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold and corresponding revenue generated per 'vintage' item.\n",
    "vintage_items= vintagedf.groupby(\n",
    "   ['display_name']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "vintage_items.sort_values(by=['amount'], inplace=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we discover this dataset includes display items that are NOT vintage\n",
    "vintage_items #includes 'Perforated' and 'Veg' items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all rows with display_name ' Perforated' and 'Veg'\n",
    "vintagedf = vintagedf[~vintagedf.display_name.str.contains('Perforated')]\n",
    "vintagedf = vintagedf[~vintagedf.display_name.str.contains('Veg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold and corresponding revenue generated per 'vintage' item.\n",
    "vintage_items= vintagedf.groupby(\n",
    "   ['display_name']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "vintage_items.sort_values(by=['amount'], inplace=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we observe that the non-vintage items have been removed\n",
    "vintage_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data frame by year and extract a number of stats per year\n",
    "vintage_revenuerank = vintagedf.groupby(\n",
    "   ['year']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "vintage_revenuerank.sort_values(by=['year'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintage_revenuerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vintage Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PIVOT TABLE\n",
    "vintage_table = pd.pivot_table(vintagedf, index=\"display_name\",columns='year',\n",
    "                              values =[\"amount\",\"quantity\"],aggfunc=sum, margins=True)\n",
    "\n",
    "#sort the pivot table\n",
    "vintage_table.sort_values(by=('amount','All'), ascending=False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "vintage_table.columns =[s1 + '_' + str(s2) for (s1,s2) in vintage_table.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposed column order\n",
    "columnsTitles = ['quantity_2015','amount_2015','quantity_2016','amount_2016','quantity_2017','amount_2017','quantity_2018','amount_2018','quantity_2019','amount_2019','quantity_All','amount_All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-arrange column indexes(order) based on above columnsTitles\n",
    "vintage_table = vintage_table.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first row\n",
    "vintage_table = vintage_table.drop(vintage_table.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintage_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vintage dataframe second approach\n",
    "This is asecond approach to creating the vintage dataframe by using the dispaly_names.We observe that the both approaches result to the same dataframe.Any approach can therefore be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miniwallet vintage dataframe\n",
    "miniwalletvintage = df_clean[(df_clean.display_name == 'Miniwallet Vintage Black') \n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Blue') \n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Brown')\n",
    "                             | (df_clean.display_name ==  'Miniwallet Vintage Chocolate')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Cognac')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Cognac-Rust')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Concrete')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Grey')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Grey-Black')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Ochre')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Olive-Black')\n",
    "                             | (df_clean.display_name == 'Miniwallet Vintage Rose')\n",
    "                             | (df_clean.display_name == 'PromoSales Miniwallet Vintage Cognac-Rust')]\n",
    "                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniwalletvintage.head()#preview the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slimwallet vintage dataframe\n",
    "slimwalletvintage = df_clean[(df_clean.display_name == 'Slimwallet Vintage Black') \n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Blue') \n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Blue Silver')\n",
    "                             | (df_clean.display_name ==  'Slimwallet Vintage Chocolate')\n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Cognac')\n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Cognac-Rust')                            \n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Grey-Black')\n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Ochre')\n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Olive-Black')\n",
    "                             | (df_clean.display_name == 'Slimwallet Vintage Brown')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slimwalletvintage.head()#preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twinwallet vintage dataframe\n",
    "twinwalletvintage = df_clean[(df_clean.display_name == 'Twinwallet Vintage Black') \n",
    "                             | (df_clean.display_name == 'Twinwallet Vintage Blue') \n",
    "                             | (df_clean.display_name == 'Twinwallet Vintage Brown')\n",
    "                             | (df_clean.display_name ==  'Twinwallet Vintage Chocolate')\n",
    "                             | (df_clean.display_name == 'Twinwallet Vintage Cognac')\n",
    "                             | (df_clean.display_name == 'Twinwallet Vintage Ochre')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twinwalletvintage.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the miniwallet,twinwallet and slimwallet vintage dataframe\n",
    "vintagedf2 = pd.concat([miniwalletvintage, slimwalletvintage, twinwalletvintage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this new column will help us uniquely identify vintage dataframe of data once it is combined with the original and matte dataframes\n",
    "#insert new column with value 'vint'\n",
    "vintagedf2['collection']='vint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintagedf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data frame by year and extract a number of stats per year\n",
    "vintage_rank = vintagedf2.groupby(\n",
    "   ['year']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "vintage_rank.sort_values(by=['year'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists the total revenue amount and total items sold per year for vintage collection items.\n",
    "vintage_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vintagedf2 Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PIVOT TABLE\n",
    "vintagedf2_table = pd.pivot_table(vintagedf2, index=\"display_name\",columns='year',\n",
    "                              values =[\"amount\",\"quantity\"],aggfunc=sum, margins=True)\n",
    "\n",
    "#sort the pivot table\n",
    "vintagedf2_table.sort_values(by=('amount','All'), ascending=False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintagedf2_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "vintagedf2_table.columns =[s1 + '_' + str(s2) for (s1,s2) in vintagedf2_table.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposed column order\n",
    "columnsTitles = ['quantity_2015','amount_2015','quantity_2016','amount_2016','quantity_2017','amount_2017','quantity_2018','amount_2018','quantity_2019','amount_2019','quantity_All','amount_All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-arrange column indexes(order) based on above columnsTitles\n",
    "vintagedf2_table = vintagedf2_table.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first row\n",
    "vintagedf2_table = vintagedf2_table.drop(vintagedf2_table.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintagedf2_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "vintagedf2.to_csv('vintagedataframe.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id='original'></a>\n",
    " ### ORIGINAL PRODUCT ANALYSIS\n",
    " Original collection consists of the following display items;\n",
    " \n",
    "       'Miniwallet Original Black',\n",
    "       'Miniwallet Original Black Exclusive',\n",
    "       'Miniwallet Original Black Red Exclusive',\n",
    "       'Miniwallet Original Bordeaux', 'Miniwallet Original Cognac-Brown',\n",
    "       'Miniwallet Original Cognac-Rust', 'Miniwallet Original Dark Brown',\n",
    "       'Miniwallet Original Emerald', 'Miniwallet Original Fuchsia',\n",
    "       'Miniwallet Original Green', 'Miniwallet Original Indigo',\n",
    "       'Miniwallet Original Natural', 'Miniwallet Original Navy',\n",
    "       'Miniwallet Original Navy-Blue', 'Miniwallet Original Red Lipstick',\n",
    "       'Miniwallet Original Red-Red', \n",
    "       \n",
    "       'Slimwallet Original Black', 'Slimwallet Original Bordeaux',\n",
    "       'Slimwallet Original Cognac-Brown', 'Slimwallet Original Green',\n",
    "       'Slimwallet Original Navy',\n",
    " \n",
    "       'Twinwallet Original Black', 'Twinwallet Original Black Exclusive',\n",
    "       'Twinwallet Original Cognac-Brown', 'Twinwallet Original Fuchsia',\n",
    "       'Twinwallet Original Green', 'Twinwallet Original Red Lipstick',\n",
    "       'Twinwallet Original Red-Red',\n",
    "       \n",
    "        'Limited Miniwallet Original Black/Red\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only type of material of interest ('Original')\n",
    "#This dataset contains items that are not 'original'.THese non original items are; 'Slimwallet Black Red Exclusive','Slimwallet Black Exclusive'and'Miniwallet Royal Blue Orange'\n",
    "# The dataset is missing some original display items.These missing dispaly items are;\n",
    "#'Limited Miniwallet Original Black/Red','Miniwallet Original Red Lipstick', 'Miniwallet Original Natural'\n",
    "#'Miniwallet Original Indigo'and 'Miniwallet Original Cognac-Rust'\n",
    "\n",
    "incompleteoriginaldf =df_clean[(df_clean.type_of_material == 'Original')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all rows with non original dispaly itemms. Delete rows with display_name 'Slimwallet Black Red Exclusive','Slimwallet Black Exclusive' and 'Miniwallet Royal Blue Orange'\n",
    "incompleteoriginaldf = incompleteoriginaldf[~incompleteoriginaldf.display_name.str.contains('Slimwallet Black Red Exclusive')]\n",
    "incompleteoriginaldf = incompleteoriginaldf[~incompleteoriginaldf.display_name.str.contains('Slimwallet Black Exclusive')]\n",
    "incompleteoriginaldf = incompleteoriginaldf[~incompleteoriginaldf.display_name.str.contains('Miniwallet Royal Blue Orange')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with the missing display items\n",
    "#these missing items are'Limited Miniwallet Original Black/Red','Miniwallet Original Red Lipstick', 'Miniwallet Original Natural'\n",
    "#'Miniwallet Original Indigo','Miniwallet Original Cognac-Rust'\n",
    "missing_original = df_clean[(df_clean.display_name == 'Limited Miniwallet Original Black/Red') \n",
    "                            | (df_clean.display_name == 'Miniwallet Original Red Lipstick')\n",
    "                            | (df_clean.display_name == 'Miniwallet Original Natural')\n",
    "                            | (df_clean.display_name == 'Miniwallet Original Indigo')\n",
    "                            | (df_clean.display_name == 'Miniwallet Original Cognac-Rust')]                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine 'incompleteoriginaldf' and 'missing_original'\n",
    "originaldf = pd.concat([incompleteoriginaldf, missing_original])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this new column will help us uniquely identify original dataframe of data once it is combined with the vintage and matte dataframes\n",
    "#insert new column with value 'org'\n",
    "originaldf['collection']='org'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "originaldf.to_csv('originaldataframe.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold and corresponding revenue generated per 'original' item.\n",
    "original_items= originaldf.groupby(\n",
    "   ['shipping_country']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "original_items.sort_values(by=['amount'], inplace=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_items # includes 'Slimwallet Black Red Exclusive','Slimwallet Black Exclusive','Miniwallet Royal Blue Orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data frame by year and extract a number of stats per year\n",
    "original_rank = originaldf.groupby(\n",
    "   ['year']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "original_rank.sort_values(by=['year'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists the total revenue amount and total items sold per year for original collection items.\n",
    "original_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PIVOT TABLE\n",
    "original_table = pd.pivot_table(originaldf, index=\"display_name\",columns='year',\n",
    "                              values =[\"amount\",\"quantity\"],aggfunc=sum, margins=True)\n",
    "\n",
    "#sort the pivot table\n",
    "original_table.sort_values(by=('amount','All'), ascending=False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "original_table.columns =[s1 + '_' + str(s2) for (s1,s2) in original_table.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposed column order\n",
    "columnsTitles = ['quantity_2015','amount_2015','quantity_2016','amount_2016','quantity_2017','amount_2017','quantity_2018','amount_2018','quantity_2019','amount_2019','quantity_All','amount_All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-arrange column indexes(order) based on above columnsTitles\n",
    "original_table = original_table.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first row\n",
    "original_table = original_table.drop(original_table.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_table # print pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id='matte'></a>\n",
    " ### MATTE PRODUCT ANALYSIS\n",
    " Matte dataframe consists of;\n",
    "     \n",
    "       'Miniwallet Matte Black & Red', 'Miniwallet Matte Black & Yellow',\n",
    "       'Miniwallet Matte Blue', 'Miniwallet Matte Brick-Black',\n",
    "       'Miniwallet Matte Chalk', 'Miniwallet Matte Green',\n",
    "       'Miniwallet Matte Green-Black', 'Miniwallet Matte Grey-Black',\n",
    "       'Miniwallet Matte Lilac-Black', 'Miniwallet Matte Nightblue',\n",
    "       'Miniwallet Matte Petrol', 'Miniwallet Matte Pink',\n",
    "       'Miniwallet Matte Purple',       \n",
    "       \n",
    "       'Slimwallet Matte Black',\n",
    "       'Slimwallet Matte Black & Red', 'Slimwallet Matte Black & Yellow',\n",
    "       'Slimwallet Matte Green', 'Slimwallet Matte Green-Black',\n",
    "       'Slimwallet Matte Grey-Black', 'Slimwallet Matte Nightblue',\n",
    "       'Slimwallet Matte Petrol',\n",
    "       \n",
    "       'Twinwallet Matte Black', 'Twinwallet Matte Blue',\n",
    "       'Twinwallet Matte Blue Silver', 'Twinwallet Matte Green',\n",
    "       'Twinwallet Matte Purple',\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only type of material of interest ('Matte')\n",
    "mattedf =df_clean[(df_clean.type_of_material == 'Matte')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this new column will help us uniquely identify matte dataframe of data once it is combined with the vintage and original dataframes\n",
    "#insert new column with value 'mat'\n",
    "mattedf['collection']='mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "mattedf.to_csv('mattedataframe.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mattedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold and corresponding revenue generated per 'matte' item.\n",
    "matte_items= mattedf.groupby(\n",
    "   ['display_name','shipping_country']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "matte_items.sort_values(by=['amount'], inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matte_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data frame by year and extract a number of stats per year\n",
    "matte_rank = mattedf.groupby(\n",
    "   ['year']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "matte_rank.sort_values(by=['year'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists the total revenue amount and total items sold per year for matte collection items.\n",
    "matte_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matte Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PIVOT TABLE\n",
    "matte_table = pd.pivot_table(mattedf, index=\"display_name\",columns='year',\n",
    "                              values =[\"amount\",\"quantity\"],aggfunc=sum, margins=True)\n",
    "\n",
    "#sort the pivot table\n",
    "matte_table.sort_values(by=('amount','All'), ascending=False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matte_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "matte_table.columns =[s1 + '_' + str(s2) for (s1,s2) in matte_table.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposed column order\n",
    "columnsTitles = ['quantity_2015','amount_2015','quantity_2016','amount_2016','quantity_2017','amount_2017','quantity_2018','amount_2018','quantity_2019','amount_2019','quantity_All','amount_All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-arrange column indexes(order) based on above columnsTitles\n",
    "matte_table = matte_table.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first row\n",
    "matte_table = matte_table.drop(matte_table.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matte_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='collectionsdf'></a>\n",
    "## COMBINE VINTAGE, ORGINAL AND MATTE DATAFRAMES INTO ONE 'collectionsdf'\n",
    "\n",
    "### collectionsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine vintage original and matte dataframes into one 'collectionsdf' dataframe\n",
    "collectionsdf = pd.concat([vintagedf, originaldf, mattedf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionsdf.head()#preview first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionsdf.tail()# preview the last five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "collectionsdf.to_csv('combined_collections_dataframe.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='shipping_country'></a>\n",
    "## VARIABLE: shipping_country\n",
    "\n",
    "This column is important as it lists all the countries the items shipped itams to. As previously indicated in the objective, we shall filter the collctions dataset to only the top five revenue generating countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shipping_country.describe()#overview of variable; count, unique, top,freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries the business shipped items to\n",
    "print (df_clean.shipping_country.cat.categories)# Get list of categories in categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Sales transactions per country\n",
    "df_clean.shipping_country.value_counts() #count per category(Transactions per country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print number of missing values in thi column\n",
    "print(df_clean.shipping_country.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold and corresponding revenue generated per country\n",
    "countryrevenuerank= df_clean.groupby(\n",
    "   ['shipping_country']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "countryrevenuerank.sort_values(by=['amount'], inplace=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryrevenuerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Findings on shipping country**\n",
    "\n",
    "    Top 5 revenue generating countries are ; Netherlands,Germany, Spain, France, Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLECTIONS ANALYSIS FOR THE TOP 5 COUNTRIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COLLECTION ANALYSIS TOP FIVE COMBINED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to only top five revenue generating countries ('Netherlands', 'Germany', 'Spain', 'France' and 'Switzerland')\n",
    "topfivecombined_collectionsdf =collectionsdf[(collectionsdf.shipping_country == 'Netherlands')\n",
    "                                        | (collectionsdf.shipping_country == 'Germany')\n",
    "                                        | (collectionsdf.shipping_country == 'Spain')\n",
    "                                        | (collectionsdf.shipping_country == 'France')\n",
    "                                        | (collectionsdf.shipping_country == 'Switzerland')]                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfivecombined_collectionsdf.head() # preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfivecombined_collectionsdf.tail() #preview last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "topfivecombined_collectionsdf.to_csv('topfive_combined_collection_dataframe.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold per collection and corresponding revenue generated per country\n",
    "topfive_revenuerank= topfivecombined_collectionsdf.groupby(\n",
    "   ['shipping_country']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "topfive_revenuerank.sort_values(by=['amount'], inplace=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfive_revenuerank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Vintage, Original and Matte collections in top 5 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold per collection and corresponding revenue generated per country\n",
    "topfive_comparison= topfivecombined_collectionsdf.groupby(\n",
    "   ['collection']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "topfive_comparison.sort_values(by=['amount'], inplace=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfive_comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pivot table details quantity of items sold and revenue per collection per year.\n",
    "# PIVOT TABLE\n",
    "topfive_comparison_table = pd.pivot_table(topfivecombined_collectionsdf, index=\"collection\", columns='year',\n",
    "                              values =[\"amount\",\"quantity\"],aggfunc=sum, margins=True)\n",
    "\n",
    "#sort the pivot table\n",
    "topfive_comparison_table.sort_values(by=('amount','All'), ascending=False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfive_comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pivot table details quantity of items sold and revenue per collection per country per year.\n",
    "# PIVOT TABLE\n",
    "topfive_comparisondetailed_table = pd.pivot_table(topfivecombined_collectionsdf, index=[\"shipping_country\",\"collection\"],columns='year',\n",
    "                              values =[\"amount\",\"quantity\"],aggfunc=sum, margins=True)\n",
    "\n",
    "#sort the pivot table\n",
    "topfive_comparisondetailed_table.sort_values(by=('shipping_country'), ascending=False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfive_comparisondetailed_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vintage in top 5 contries combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter top five sub-set to only vintage collection\n",
    "topfivecombined_vintagedf = topfivecombined_collectionsdf[(topfivecombined_collectionsdf.collection == 'vint')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfivecombined_vintagedf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second approach(Both approaches are correct)\n",
    "\n",
    "#filter vintage dataframe to only top five revenue generating countries ('Netherlands', 'Germany', 'Spain', 'France' and 'Switzerland')\n",
    "topfivecombined_vintagedf2 =vintagedf[(vintagedf.shipping_country == 'Netherlands')\n",
    "                                        | (vintagedf.shipping_country == 'Germany')\n",
    "                                        | (vintagedf.shipping_country == 'Spain')\n",
    "                                        | (vintagedf.shipping_country == 'France')\n",
    "                                        | (vintagedf.shipping_country == 'Switzerland')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfivecombined_vintagedf2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total quantity of items sold per year for vintage collection and corresponding revenue generated per top 5 country\n",
    "topfivecombined_vintagedfrank= topfivecombined_vintagedf.groupby(\n",
    "   ['year']\n",
    ").agg(\n",
    "    {\n",
    "         'amount':sum,    # Sum revenue per customer\n",
    "         'quantity': sum  # get the sum of items sold per year\n",
    "         \n",
    "    }\n",
    ")\n",
    "\n",
    "topfivecombined_vintagedfrank.sort_values(by=['year'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfivecombined_vintagedfrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topfivecombined vintage Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PIVOT TABLE\n",
    "topfivecombinedvintage_table = pd.pivot_table(topfivecombined_vintagedf, index=\"shipping_country\",columns='year',\n",
    "                              values =[\"amount\",\"quantity\"],aggfunc=sum, margins=True)\n",
    "\n",
    "#sort the pivot table\n",
    "topfivecombinedvintage_table.sort_values(by=('amount','All'), ascending=False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfivecombinedvintage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "topfivecombinedvintage_table.columns =[s1 + '_' + str(s2) for (s1,s2) in topfivecombinedvintage_table.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposed column order\n",
    "columnsTitles = ['quantity_2015','amount_2015','quantity_2016','amount_2016','quantity_2017','amount_2017','quantity_2018','amount_2018','quantity_2019','amount_2019','quantity_All','amount_All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-arrange column indexes(order) based on above columnsTitles\n",
    "topfivecombinedvintage_table = topfivecombinedvintage_table.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first row\n",
    "topfivecombinedvintage_table = topfivecombinedvintage_table.drop(topfivecombinedvintage_table.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfivecombinedvintage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
